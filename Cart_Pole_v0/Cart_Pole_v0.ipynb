{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import gym\n",
    "import collections\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ffmpeg_path = 'C:\\\\Users\\\\dhzns\\\\OneDrive\\\\code\\\\ipython\\\\OpenAI_gym\\\\ffmpeg\\\\bin'\n",
    "os.environ['PATH'] = ffmpeg_path + ';' + os.environ['PATH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#File Path\n",
    "filepath_ckpt  = \"./ckpt/CartPole_yt.ckpt\" #weight saver check point file path\n",
    "batch_size = 20\n",
    "learning_rate = 0.1\n",
    "input_size = 4\n",
    "output_size = 2\n",
    "h_size = 128\n",
    "discount_rate = 0.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DQN:\n",
    "    def __init__(self, session, input_size, output_size, name=\"main\"):\n",
    "        self.session = session\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.net_name = name\n",
    "        \n",
    "        self._build_network(h_size = h_size, l_rate = learning_rate)\n",
    "        \n",
    "    def _build_network(self, h_size=10, l_rate=0.05):\n",
    "        with tf.name_scope(self.net_name) as scope:\n",
    "            self._X = tf.placeholder(tf.float32, [None, input_size], name='Observation_placeholder')\n",
    "            self._Y = tf.placeholder(tf.float32, [None, output_size], name='Q_placeholder')\n",
    "\n",
    "            W1 = tf.Variable(tf.truncated_normal([self.input_size, h_size], dtype=tf.float32), trainable=True, name='weight')\n",
    "            l1p = tf.matmul(self._X,W1)\n",
    "            l1 = tf.nn.tanh(l1p)\n",
    "        \n",
    "#             tf.contrib.layers.batch_norm(l1)\n",
    "            W2 = tf.Variable(tf.truncated_normal([h_size, output_size], dtype=tf.float32), trainable=True, name='weight')\n",
    "            l2p = tf.matmul(l1, W2)\n",
    "#             l2 = tf.nn.relu(l2p)\n",
    "      \n",
    "#             tf.contrib.layers.batch_norm(l2)\n",
    "#             W3 = tf.Variable(tf.truncated_normal([h_size, h_size], dtype=tf.float32), trainable=True, name='weight')\n",
    "#             l3p = tf.matmul(l2, W3)\n",
    "#             l3 = tf.nn.relu(l3p)\n",
    "        \n",
    "#             tf.contrib.layers.batch_norm(l3)\n",
    "#             W4 = tf.Variable(tf.truncated_normal([h_size, self.output_size], dtype=tf.float32), trainable=True, name='weight')\n",
    "#             l4p = tf.matmul(l3, W4)\n",
    "#             l4 = tf.nn.relu(l4p)\n",
    "            \n",
    "            self.logits = l2p\n",
    "#             self.prob = tf.nn.tanh(self.logits)\n",
    "\n",
    "            self._loss = tf.reduce_sum(tf.square(self._Y - self.logits))\n",
    "            self._train = tf.train.AdamOptimizer(learning_rate=l_rate).minimize(self._loss)\n",
    "            \n",
    "    def predict(self, state):\n",
    "        x = np.reshape(state, [1, self.input_size])\n",
    "        return self.session.run(self.logits, feed_dict={self._X: x})\n",
    "    \n",
    "    def update(self, x_stack, y_stack):\n",
    "        return self.session.run([self._loss, self._train], feed_dict={self._X: x_stack, self._Y: y_stack})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def replay_train(mainDQN, targetDQN, train_batch):\n",
    "    x_stack = np.empty(0).reshape(0, input_size)\n",
    "    y_stack = np.empty(0).reshape(0, output_size)\n",
    "    \n",
    "    for state, action, reward, next_state, done in train_batch:\n",
    "        Q = mainDQN.predict(state)\n",
    "        \n",
    "        if done:\n",
    "            Q[0, action]= reward\n",
    "        else:\n",
    "            Q[0, action]= reward + discount_rate * np.max(targetDQN.predict(next_state))\n",
    "        \n",
    "        y_stack = np.vstack([y_stack, Q])\n",
    "        x_stack = np.vstack([x_stack, state])\n",
    "        \n",
    "    return mainDQN.update(x_stack, y_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-30 20:57:48,526] Making new env: CartPole-v0\n",
      "[2017-08-30 20:57:48,548] Clearing 20 monitor files from previous run (because force=True was provided)\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('CartPole-v0')\n",
    "env = gym.wrappers.Monitor(env, './tmp/cartpole-v0-experiment2', force=True )\n",
    "max_episode = 2000\n",
    "replay_buffer = collections.deque()\n",
    "REPLAY_MEMORY = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mainDQN = DQN(sess, input_size, output_size, name=\"main\")\n",
    "targetDQN = DQN(sess, input_size, output_size, name=\"target\")\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# saver.restore(sess, filepath_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_copy_var_ops(*, dest_scope_name=\"target\", src_scope_name=\"main\"):\n",
    "    op_holder = []\n",
    "    \n",
    "    src_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=src_scope_name)\n",
    "    dest_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=dest_scope_name)\n",
    "    \n",
    "    for src_var, dest_var in zip(src_vars, dest_vars):\n",
    "        op_holder.append(dest_var.assign(src_var.value()))\n",
    "        \n",
    "    return op_holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "copy_ops = get_copy_var_ops(dest_scope_name=\"target\", src_scope_name = \"main\")\n",
    "sess.run(copy_ops)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-30 20:57:51,791] Starting new video recorder writing to C:\\Users\\dhzns\\OneDrive\\code\\ipython\\OpenAI_gym\\tmp\\cartpole-v0-experiment2\\openaigym.video.0.12132.video000000.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 29 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-30 20:57:54,160] Starting new video recorder writing to C:\\Users\\dhzns\\OneDrive\\code\\ipython\\OpenAI_gym\\tmp\\cartpole-v0-experiment2\\openaigym.video.0.12132.video000001.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss :  10789.2\n",
      "Episode finished after 121 timesteps\n",
      "Loss :  6637.59\n",
      "Episode finished after 200 timesteps\n",
      "Loss :  391.818\n",
      "Episode finished after 36 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-30 20:57:58,400] Starting new video recorder writing to C:\\Users\\dhzns\\OneDrive\\code\\ipython\\OpenAI_gym\\tmp\\cartpole-v0-experiment2\\openaigym.video.0.12132.video000008.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss :  106.057\n",
      "Episode finished after 64 timesteps\n",
      "Loss :  525.122\n",
      "Episode finished after 38 timesteps\n",
      "Loss :  6661.28\n",
      "Episode finished after 200 timesteps\n",
      "Loss :  632.247\n",
      "Episode finished after 200 timesteps\n",
      "Loss :  412.549\n",
      "Episode finished after 200 timesteps\n",
      "Loss :  83.3614\n",
      "Episode finished after 200 timesteps\n",
      "Loss :  46.5372\n",
      "Episode finished after 200 timesteps\n",
      "Loss :  79.5479\n",
      "Episode finished after 200 timesteps\n",
      "Loss :  9984.92\n",
      "Episode finished after 200 timesteps\n",
      "Loss :  632.792\n",
      "Episode finished after 200 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-30 20:58:02,892] Starting new video recorder writing to C:\\Users\\dhzns\\OneDrive\\code\\ipython\\OpenAI_gym\\tmp\\cartpole-v0-experiment2\\openaigym.video.0.12132.video000027.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss :  196.734\n",
      "Episode finished after 200 timesteps\n",
      "Loss :  55.5016\n",
      "Episode finished after 200 timesteps\n",
      "Loss :  18.9841\n",
      "Episode finished after 200 timesteps\n",
      "Loss :  36.0502\n",
      "Episode finished after 200 timesteps\n",
      "Loss :  40.0979\n",
      "Episode finished after 200 timesteps\n",
      "Loss :  40.5958\n",
      "Episode finished after 200 timesteps\n",
      "Loss :  30.5854\n",
      "Episode finished after 200 timesteps\n",
      "Loss :  37.7919\n",
      "Episode finished after 200 timesteps\n",
      "Loss :  33.6748\n",
      "Episode finished after 200 timesteps\n",
      "Loss :  19.8382\n",
      "Episode finished after 200 timesteps\n",
      "Loss :  26.6069\n",
      "Episode finished after 200 timesteps\n",
      "Loss :  20.4417\n",
      "Episode finished after 200 timesteps\n",
      "Loss :  35.8241\n",
      "Episode finished after 200 timesteps\n",
      "Loss :  32.6488\n",
      "Episode finished after 200 timesteps\n",
      "Loss :  53.0289\n",
      "Episode finished after 200 timesteps\n",
      "Loss :  42.7408\n",
      "Episode finished after 200 timesteps\n",
      "Loss :  23.3931\n",
      "Episode finished after 200 timesteps\n",
      "Loss :  29.565\n",
      "Episode finished after 200 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-30 20:58:12,534] Starting new video recorder writing to C:\\Users\\dhzns\\OneDrive\\code\\ipython\\OpenAI_gym\\tmp\\cartpole-v0-experiment2\\openaigym.video.0.12132.video000064.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss :  41.6347\n",
      "Episode finished after 200 timesteps\n",
      "Loss :  49.9567\n",
      "Episode finished after 200 timesteps\n",
      "Loss :  33.3239\n",
      "Episode finished after 200 timesteps\n",
      "Loss :  23.1768\n",
      "Episode finished after 200 timesteps\n",
      "Loss :  30.2106\n",
      "Episode finished after 200 timesteps\n",
      "Loss :  12.5499\n",
      "Episode finished after 200 timesteps\n",
      "Loss :  36.5756\n",
      "Episode finished after 200 timesteps\n",
      "Loss :  19.4979\n",
      "Episode finished after 200 timesteps\n",
      "Loss :  25.5268\n",
      "Episode finished after 200 timesteps\n",
      "Loss :  44.211\n",
      "Episode finished after 200 timesteps\n",
      "Loss :  30.8338\n",
      "Episode finished after 200 timesteps\n",
      "Loss :  44.5301\n",
      "Episode finished after 200 timesteps\n",
      "Loss :  34.1146\n",
      "Episode finished after 200 timesteps\n",
      "Loss :  39.2852\n",
      "Episode finished after 200 timesteps\n",
      "Loss :  22.4312\n",
      "Episode finished after 200 timesteps\n",
      "Loss :  29.5449\n",
      "Episode finished after 200 timesteps\n",
      "Loss :  37.227\n",
      "Episode finished after 200 timesteps\n",
      "Loss :  33.8985\n",
      "Episode finished after 200 timesteps\n",
      "Loss :  40.5463\n",
      "Episode finished after 200 timesteps\n",
      "Loss :  19.8678\n",
      "Episode finished after 200 timesteps\n",
      "Loss :  52.7588\n",
      "Episode finished after 200 timesteps\n",
      "Loss :  54.9549\n",
      "Episode finished after 200 timesteps\n",
      "Loss :  67.1866\n",
      "Episode finished after 200 timesteps\n",
      "Loss :  42.4033\n",
      "Episode finished after 200 timesteps\n",
      "Loss :  32.8022\n",
      "Episode finished after 200 timesteps\n",
      "Loss :  29.1426\n",
      "Episode finished after 200 timesteps\n",
      "Loss :  53.0453\n",
      "Episode finished after 200 timesteps\n",
      "Loss :  68.0573\n",
      "Episode finished after 200 timesteps\n",
      "Loss :  16.1791\n",
      "Episode finished after 200 timesteps\n",
      "Loss :  25.4123\n",
      "Episode finished after 200 timesteps\n",
      "Loss :  51.4654\n",
      "Episode finished after 200 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-30 20:58:26,652] Starting new video recorder writing to C:\\Users\\dhzns\\OneDrive\\code\\ipython\\OpenAI_gym\\tmp\\cartpole-v0-experiment2\\openaigym.video.0.12132.video000125.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss :  50.2951\n"
     ]
    }
   ],
   "source": [
    "p= 0.2\n",
    "gamma = 0.8\n",
    "for i_episode in range(1000):\n",
    "    if p > 0:\n",
    "        p -=0.01\n",
    "    s = env.reset()\n",
    "    for t in range(201):\n",
    "#         env.render()\n",
    "        e = random.random()\n",
    "#         print(e)\n",
    "        if e < p:\n",
    "            a = env.action_space.sample()\n",
    "        else:\n",
    "#             print(\"select\")\n",
    "            a = np.argmax(mainDQN.predict(s))\n",
    "#         print(action)\n",
    "        \n",
    "        #get new state    \n",
    "        s1, rwd, done, _ = env.step(a)\n",
    "        \n",
    "        if t == 199:\n",
    "            replay_buffer.append((s, a, rwd, s1, done))\n",
    "            if len(replay_buffer) > REPLAY_MEMORY:\n",
    "                replay_buffer.popleft()\n",
    "            break\n",
    "        if done:\n",
    "            if t <10:\n",
    "                rwd = -200\n",
    "            elif t< 50:\n",
    "                rwd = -150\n",
    "            elif t< 100:\n",
    "                rwd = -100\n",
    "            elif t< 150:\n",
    "                rwd = -50\n",
    "        replay_buffer.append((s, a, rwd, s1, done))\n",
    "        if len(replay_buffer) > REPLAY_MEMORY:\n",
    "            replay_buffer.popleft()\n",
    "        \n",
    "        if done:\n",
    "            break\n",
    "            \n",
    "        s = s1\n",
    "        \n",
    "    \n",
    "            \n",
    "        \n",
    "    if i_episode % 2 == 0: \n",
    "        print(\"Episode finished after {} timesteps\".format(t+1))\n",
    "\n",
    "        for _ in range(50):\n",
    "            mini_batch = random.sample(replay_buffer, batch_size)\n",
    "            loss, _ = replay_train(mainDQN, targetDQN, mini_batch)\n",
    "        print(\"Loss : \", loss)\n",
    "        sess.run(copy_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver.save(sess, filepath_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gym.upload('./tmp/cartpole-v0-experiment2', api_key='sk_R6pSeGWSRfSWyCxZP08FiQ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the test\n",
    "env = gym.make('CartPole-v0')\n",
    "for i_episode in range(20):\n",
    "    s = env.reset()\n",
    "    for t in range(201):\n",
    "        env.render()\n",
    "        a = np.argmax(mainDQN.predict(s))\n",
    "        s, rwd, done, _ = env.step(a)\n",
    "        \n",
    "        if done:\n",
    "            print(\"Episode finished after {} timesteps\".format(t+1))\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "env.close()\n",
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
